apiVersion: eksctl.io/v1alpha5  # eksctl configuration API version
kind: ClusterConfig             # Defines this file as a cluster config file

metadata:
  name: kartstream-eks          # The EKS cluster name
  region: ap-south-1            # AWS region where the cluster (and node group) will be created

managedNodeGroups:
  - name: database-nodes           # Name identifier for the node group
    instanceType: c7i-flex.large  # EC2 instance type for the nodes in this group
    
    minSize: 1                    # Minimum number of nodes in this node group autoscaling group
    maxSize: 2                    # Maximum number of nodes allowed in the node group autoscaling
    desiredCapacity: 1            # Number of nodes to start with initially
    
    volumeSize: 20                # Size in GiB of the root EBS volume for each node
    amiType: AL2_x86_64           # Specifies the Amazon Machine Image type (Amazon Linux 2, 64 bit here)
    
    subnets:
      - subnet-03a89b25a021e7af6 # List of subnet IDs where nodes will be launched (must belong to cluster VPC)
    
    privateNetworking: true      # Whether nodes should launch without public IP addresses (false means enable public IP)
    
    nodeRoleARN: arn:aws:iam::988677443148:role/eksNodegroupRole  
                                # The IAM role ARN assumed by the nodes for AWS permissions
    
    # Attaches this security group to every EC2 instance in the node group
    securityGroups:
      attachIDs: ["sg-0eeb3af41a8199d3d"]  # AWS Security Group ID(s)
    
    # Kubernetes labels applied to nodes, useful for scheduling with nodeSelector or affinity on pods
    labels:
      app: redis-cart              # Custom label 'role' to identSify nodes fulfilling frontend responsibilities
      
    # AWS EC2 resource tags applied to all instances launched by this node group
    tags:
      Project: kartstream        # Tag key-value pair for project name
      Stack: database            # Tag key-value pair to identify stack/layer
    
    # Taints assigned to nodes that dictate pod scheduling restrictions (only pods with matching tolerations will schedule)
    taints:
      - key: role
        value: database
        effect: NoSchedule        # Denies pods without matching toleration from being scheduled on these nodes
    
    # Rolling update configuration controls how nodes are updated/replaced in the group in a controlled way
    updateConfig:
      maxUnavailable: 1          # Allows only 1 node to be updated/recreated at a time during rolling updates
